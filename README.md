# Bandits

Multi-arm bandit implementations in R for (i) e-greedy, (ii) softmax and (iii) ucb, algorithm variations and Monte-Carlo simulation framework for testing.

Implementations are based on "Bandit Algorithms for Website Optimization" by J. White, O-Reilly, http://shop.oreilly.com/product/0636920027393.do
